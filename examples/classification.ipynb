{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hydra import initialize_config_dir, compose\n",
    "config_dir = os.path.abspath('../configs')\n",
    "with initialize_config_dir(config_dir=config_dir, version_base=\"1.1\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config\",\n",
    "        overrides=[\n",
    "            \"model=vit\",\n",
    "            \"data=domars16k\",\n",
    "            \"seed=0\",\n",
    "            \"training.batch_size=16\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 0\n",
      "task: classification\n",
      "data:\n",
      "  split:\n",
      "    train: 0.6\n",
      "    val: 0.2\n",
      "    test: 0.2\n",
      "  valid_image_extensions:\n",
      "  - jpg\n",
      "  - JPG\n",
      "  - jpeg\n",
      "  - JPEG\n",
      "  - png\n",
      "  - PNG\n",
      "  - tif\n",
      "  - TIF\n",
      "  name: DoMars16k\n",
      "  status: ready\n",
      "  data_dir: /data/hkerner/MarsBench/Datasets/DoMars16K/data/\n",
      "  annot_csv: /data/hkerner/MarsBench/Datasets/DoMars16K/annotation.csv\n",
      "  num_classes: 15\n",
      "  model_loc: /data/hkerner/MarsBench/Models/DoMars16K/${model.name}/\n",
      "model:\n",
      "  classification:\n",
      "    name: VisionTransformer\n",
      "    class_path: src.models.classification.ViT\n",
      "    status: ready\n",
      "    pretrained: true\n",
      "    freeze_layers: true\n",
      "    input_size:\n",
      "    - 3\n",
      "    - 224\n",
      "    - 224\n",
      "transforms:\n",
      "  image_size:\n",
      "  - 224\n",
      "  - 224\n",
      "  mean:\n",
      "  - 0.485\n",
      "  - 0.456\n",
      "  - 0.406\n",
      "  std:\n",
      "  - 0.229\n",
      "  - 0.224\n",
      "  - 0.225\n",
      "training:\n",
      "  batch_size: 16\n",
      "  num_workers: 4\n",
      "  max_epochs: 10\n",
      "optimizer:\n",
      "  name: adam\n",
      "  lr: 0.001\n",
      "criterion:\n",
      "  name: cross_entropy\n",
      "test:\n",
      "  data:\n",
      "    status:\n",
      "    - ready\n",
      "    subset_size: 100\n",
      "  model:\n",
      "    status:\n",
      "    - ready\n",
      "    with_tuple_output:\n",
      "    - InceptionV3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import *\n",
    "from src.utils.transforms import get_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just for explaination purpose, doesn't need to be run\n",
    "# train_transform, val_transform = get_transforms(cfg)\n",
    "# train_dataset, val_dataset, test_dataset = get_dataset(cfg, train_transform, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmalaviy/.conda/envs/vl/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from src.data.mars_datamodule import MarsDataModule\n",
    "data_module = MarsDataModule(cfg)\n",
    "data_module.setup()\n",
    "\n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()\n",
    "test_loader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from src.models.classification.ViT import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmalaviy/.conda/envs/vl/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/vmalaviy/.conda/envs/vl/lib/python3.11/site-pa ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/vmalaviy/.conda/envs/vl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "model = ViT(cfg)\n",
    "trainer = Trainer(max_epochs=cfg.training.max_epochs, fast_dev_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model     | VisionTransformer | 303 M  | train\n",
      "1 | criterion | CrossEntropyLoss  | 0      | train\n",
      "--------------------------------------------------------\n",
      "15.4 K    Trainable params\n",
      "303 M     Non-trainable params\n",
      "303 M     Total params\n",
      "1,213.268 Total estimated model params size (MB)\n",
      "297       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495df47db06c489b88dec8c556c0867c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81aaacbfde4044b2b9181592dfa320d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "trainer.fit(\n",
    "    model, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdd5692fe4e41dfbdb5326c53cfc514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.25            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.343736410140991     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.25           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.343736410140991    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 2.343736410140991, 'test_acc': 0.25}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "trainer.test(\n",
    "    model, dataloaders=test_loader\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
